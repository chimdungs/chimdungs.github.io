---
title: RaDe-GS, arXiv preprint
author: jiyoung
date: 2025-02-07 18:34:00 +0800
categories: [Paper Review]
tags: [Surface reconstruction, stereo vision, Graphics]
---
<script type="text/javascript">
  MathJax = {
    tex: {
      inlineMath: [['$', '$'], ['\\(', '\\)']]
    }
  };
</script>
<script type="text/javascript" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

## RaDe-GS: Rasterizing Depth in Gaussian Splatting
- 인용도 많이 됐고 나온지 꽤 됐는데 아직 아카이브이길래 아마 cvpr2025 이번에 내지 않았을까 싶은데...
- [GOF(Gaussian Opacity Fields, SIGGRAPH Asia 2024)](https://arxiv.org/pdf/2404.10772) 다음에 읽기
  
---

## Abstract
- 3DGS의 이산적이고 비구조적인 특성때문에 shape accurac가 떨어지는 문제 있음
- 최근 관련 연구 중, [2D-GS](https://jyseo531.github.io/posts/2DGS/)에서는 shape reconstruction 성능을 올리기 위해, Gaussian primitives들을 이용했지만 이것은 렌더링 퀄리티랑 계산적인 효율성은 감소시키는 효과가 있음
- 그래서 본 논문에서는 *rasterized 접근법*을 통해, 3DGS의 **depth map**과 **surface normal map**을 렌더링하는 Shape reconstruction 정확성 보장
- DTU dataset에서 NeuraLangelo와 비교했을 때 CD(Chamfer Distance) error가 좋게 나옴

<br>

## Introduction
- multi-view 이미지들로부터 3D Reconstruction하는 태스크에서는 multi-view stereo 알고리즘을 통해 depth map을 얻는 것을 포함한다.
- 이렇게 얻어진 depth map으로 완전한 triangle mesh를 만드는 모델로 통합되는 것이 가능하다
- 전통적인 image-based 모델링 접근법은 꽤 정확한 결과로 depth map rendering + mesh recon이 가능하나, 고질적으로 빛나는 표면(shiny surface)이나 reflective한 유리같은 transparent surface에서 특히나 robustness가 떨어지는 한계점이 존재한다.
<br>

- explicit한 3DGS에서 surface 잘 뽑아내는 것은 어려운 문제임
  - **2DGS[Huang et al.2024]** : PSNR 수치 줄어듦
  - **GOF[Yu et al.2024]** : ray-tracing 기반 방법을 통해 광선(light ray)에 따른 Gaussian opacity를 계산하는 방법으로 high-quality surface를 뽑아냄
<br>

### Contributions
1. 본 논문에서는 raasterized 기반 방법으로 general Gaussian Splatting에서 정확한 depth map을 얻는 것을 발전시켰다.<br>
2. standard GS만큼의 computation efficiency를 가진다.
3. DTU dataset에서 shape reconstruction accuracy를 Chamfer Distance 0.69mm 달성, 5분의 학습시간 
   - 이 수치는 implicit한 representation 기반 모델인 *NeuraLangelo*(0.69mm)와 비슷
   - GS-based 방법론들(sota는 GOF)에서는 당연히 성능 더 좋았음

<br>

## Methods
- scene에 splatting된 Gaussian들과 광선에 의한 **intersection point**를 통한 솔루션을 찾음 <br>

<div style="padding: 10px; border-left: 4px solid #444; background:rgb(142, 141, 141); color: #222;">
<strong> 💡Key idea💡</strong> <br>
  > camera center로부터 각각의 Light ray에 의해 Gaussian value가 최대화되는 지점이 intersection point이다 <br>
  > intersection point들에서 <strong>Affine-projection</strong>을 시키면 <em>co-planar</em> (동일 평면상에 존재)하다 <br>
  > 그리고 이 intersection point들을 Image plane에 <strong>projection 된 depth</strong>로 정의하여 curved surface를 구할 수 있다 <br>
  > 따라서, planar equation으로 projected depth를 구하는데 이것은 rasterization에 의해 효율적으로 계산될 수 있다. 
  <br>

  > final depth map은 투명도(translucency)를 고려하여 투영된 Gaussian들 중에서 <strong>중간값 깊이(median depth)</strong>로 계산
</div>

### 1. Rasterizing Depth for Gaussian Splats
- Gaussian Splatting에서는 아래 사진처럼 **Perspective camera projection**을 **Affine transformation**을 통해 근사시켜서 더 효율적인 rendering가능하다는 것 사전에 알아두고 시작
  
  <img src="assets/img/posts_storage/RaDe-GS/IMG_F0BCE5442A9B-1.jpeg" width="400">

- standard 3DGS에서는 알파 블렌딩을 위해서 image plane에 projected된 2D Gaussian의 중심점(center)을 depth로 설정한다.
  - shape detail 포착 불가능
- 그러므로, 본 논문에서는 spatially varying depth를 rasterized method기반 방법으로 계산한다.

#### 1.1. Depth Under *Perspective Projection*
- planar equation을 얻는 본격적인 과정 이전에, perspective projection으로 camera coordinate에 대한 기본 concepts부터 먼저 이해해보자.
    ![img.png](assets/img/posts_storage/RaDe-GS/IMG_3E9EBF804532-1.jpeg)

- 위 그림에서 왼쪽의 (a)에서 보여진 것 처럼, camera center $\mathrm{o}$와 unit direction $\mathrm{v}$가 주어졌을 때, <br>
  ray 상에 $o$로부터 거리 $t$만큼 떨어져 있는 point $\mathrm{x}$는, 
  $$ \begin{align} \mathrm{x}= \mathrm{o} + t\mathrm{v} \end{align} $$
  으로 구할 수 있다.

- 이 ray에 존재하는 Gaussian value $\mathrm{G}^1(t)$는,
  $$ \begin{align} \mathrm{G}^1(t)= e^{-(\mathrm{o} + t\mathrm{v}-\mathrm{x}_c)^T\Sigma^{-1}(\mathrm{o} + t\mathrm{v}-\mathrm{x}_c)} \end{align} $$
  으로 구할 수 있다.

- 이 때, Gaussian value는 1-D function이고, 이 값이 최대화되는 지점이 3D Gaussian과 ray가 만나는 ***"intersection point"*** 라고 정의한다.
- 그 후 distance $t^*$ : intersection point와 camera center간의 거리는 위의 Gaussian value가 최대화되는 t를 찾으면 되고 구한 식은 아래처럼 됨 
  
  $$ \begin{align} t^* = \frac{\mathrm{v}^T\Sigma^{-1}(\mathrm{x}_c - \mathrm{o})}{\mathrm{v}^T\Sigma^{-1}\mathrm{v}} \end{align} $$

    (유도 과정) :

    <img src="assets/img/posts_storage/RaDe-GS/IMG_9EF21ECD5F4A-1.jpeg" width="500">

- 이렇게 유도된 distance $t^*$이 의미하는 바는, 3D Gaussian들과 광선들 집합간의 intersection들이 ***"curved surface"*** 를 나타낸다고 해석할 수 있음
  - different pixels have different depth values of $t^*$ and different viewing direction $\mathrm{v}$.
  
<br>

#### 1.2. Depth Under *Local Affine Projection*


<br>


### 2. Rasterizing Normal for Gaussian Splats
