---
title: Gaussian Opacity Fields, SIGGRAPH Asia 2024
author: jiyoung
date: 2025-02-08 10:30:00 +0800
categories: [Paper Review]
tags: [Surface reconstruction, Graphics]
---
<script type="text/javascript">
  MathJax = {
    tex: {
      inlineMath: [['$', '$'], ['\\(', '\\)']]
    }
  };
</script>
<script type="text/javascript" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

### Gaussian Opacity Fields: Efficient Adaptive Surface Reconstruction in Unbounded Scenes

## Abstract
- 3DGS의 explicit한 특성 때문에 surface reconstruction은 어려운 챌린지임
- 본 논문의 GOF는 ray-tracing 기반 3D Gaussian의 volume rendering을 통해 직접적으로 geometry를 추출하여 level-set을 확인하는 과정을 수행
  - [SuGaR](https://jyseo531.github.io/posts/SuGaR/)처럼 포아송 재건(Poisson reconstruction)을 사용하지 않으며, [2DGS](https://jyseo531.github.io/posts/2DGS/)와 [GS2Mesh](https://jyseo531.github.io/posts/GS2Mesh/)처럼 TSDF fusion을 사용하지 않음
  - surface normal을 **ray-Gaussian intersection plane**(ray와 교차하는 가우시안의 평면)을 이용하여 근사함
  - geometry extraction method로는 "*Marching Tetrahedra*"(마칭 큐브아니고 마칭-사면체)방법 사용함

<br>

## Introduction
1. NeRF 기반
  - SDF(Signed Distance Function)와 occupancy 네트워크를 사용하여 surface reconstruction을 수행
  - foreground object 복원에만 제한적임
  - e.g., Neuralangelo
  - NeRF's opacity Field로부터 real-time rendering 및 surface 추출하는 연구도 진행됨 (e.g., Binary Opacity Grids-BOG)
  
2. Marching Cube Algorithm
  - mesh extraction Algorithm
  - surface recon자체보다 NVS(novel view synthesis)에 초점이 맞춰져서 고안된 방법이라, 정규화 텀이 부족하고 다소 noisy함

3. 3DGS 기반
   - [SuGaR](https://jyseo531.github.io/posts/SuGaR/) : surface-align Gaussian들을 얻기 위해 정규화 텀 추가 & depth map으로부터 Poisson reconstruction기반 메쉬추출
   - [2DGS](https://jyseo531.github.io/posts/2DGS/) : image plane에 projected된 2D Gaussian의 property이용 + TSDF fusion이용
 - 이 방법들은 surface reconstruction 성능 향상이 되었지만, **<u>fine-grained geometry</u>**를 잡는 것과 **<u>background region</u>**을 복원하는 것에는 아직 부족하다.

4. Poisson-Reconstruction 과 TSDF Fusion의 결함
   - 포아송 재건은 Gaussian primitive에 대한 opacity(투명도), scale, rendered depth같은 정보들을 고려하지 않음
   - TSDF fusion은 얇은 구조물이나 Unbounded scene에 대한 복원 성능이 정확하지 않음
  
<br>

## Contributions
1. **Volume Rendering** 측면 :
  - projection-based 방법이랑 다르게, explicit한 **ray-Gaussian intersection**을 이용해서 volume rendering할 때의 Gaussian의 "기여도"를 결정함
  - 이러한 ray-tracing 으로부터 기반된 formula는 ray상에 존재하는 모든 Point에 존재하는 Gaussian의 opacity를 결정짓게 할 수 있음 //  여기까진 [RaDe-GS](https://jyseo531.github.io/posts/RaDe-GS/)랑 유사하다
  - "view independence" = 모든 뷰에 대해 opacity가 최소인 값을 취하면 view에 대해 독립적이다(??) : opacity field가 Poisition에 대한 함수를 전적으로 책임짐
2. **Surface normal** 측면 :
   - ray와 Gausssian사이의 intersection plane(교차 평면)에 대한 normalfh rPtks
3. **Surface extraction technique(alogirthm)** 측면 :
   - poisson recon, marching cube와는 다른 메소드
   - tetrahedra-grids(다면체 그리드)에 기반한 'Marching tetrahedra' 사용함
     - 3D Gaussian primitive중에서 3D bounding box의 코너값과 중앙값을 이용하여 다면체 메쉬의 꼭짓점 집합으로 구성하는 방법임

<br>

## Methods
### 1. Modeling
- Given multiple posed + calibrated images
- 3D scene은 3D Gaussian의 집합 $\mathcal{G}_k$은 중심점 $\mathrm{p}_k$, scaling matrix $\mathrm{S}_k$, 그리고 rotation matrix $\mathrm{R}_k$으로 파라미터화되고, 이는 쿼터니언(quaternion, 복소수의 확장형태)로 아래처럼 나타내짐 :
  
    $$\begin{align} \mathcal{G}_k(\mathrm{x}) = e^{-\frac{1}{2}(\mathrm{x}-\mathrm{p}_k)\Sigma_k^{-1}(\mathrm{x}-\mathrm{p}_k)} \end{align} $$

#### Ray Gaussian Intersection
- ray와 Gaussian이 만나는 intersection의 정도를 이용한다.
- RaDe-GS에 있던 내용이랑 겹침, 그래서 어떤 부분이 어디서부터 노벨티인지 분간이 안된다(ray tracing chapter advanced ver공부 더 해야겠다)
- "ray intersection" : 1-D Gaussian Function이 최대화되는 점
  - point $\mathrm{x} = \mathrm{o} + t\mathrm{r}$ , r은 ray direction, t는 ray의 depth

1. local coordinate system으로 point $\mathrm{x}$ 을 **변환** & scale로 normalize한다
   
   $$\begin{align} \mathrm{o}_g &= \mathrm{S}_k^{-1}\mathrm{R}_k(\mathrm{o}-\mathrm{p}_k) \\
                  \mathrm{r}_g &= \mathrm{S}_k^{-1}\mathrm{R}_k\mathrm{r} \\
                  \mathrm{x}_g &= \mathrm{o}_g + t\mathrm{r}_g \end{align} $$

2. ray 선 상에 존재하는 depth t에서의 **1-D Gaussian value** :
   
   $$\begin{align} \mathcal{G}_k(\mathrm{t}) = e^{-\frac{1}{2}\mathrm{x}_g^T\mathrm{x}_g} = e^{-\frac{1}{2}(\mathrm{r}_g^T\mathrm{r}_gt^2 + 2\mathrm{o}_g^T\mathrm{r}_gt + \mathrm{o}_g^T\mathrm{o}_g)} \end{align}$$
 
3. 위의 가우시안 value가 t에 대한 quadratic term(이차형식)을 포함하고 있으므로 미분 이용해서 **최대화**되는 지점의 $t^*$을 유도 가능(RaDe-GS review에서 했음) :
   
   $$\begin{align} t^* = -\frac{B}{A} \end{align} $$

   where, $A =\mathrm{r}_g^T\mathrm{r}_g ,$  $B = \mathrm{o}_g^T\mathrm{r}_g$ <br>
   이렇게 구한 ray-Gaussian intersection은 world space에서 바로(directly) 구해질 수 있다는 점에서 surface normal구할 때도 유용한 특성임

4. "Gaussian $\mathcal{G}_k$에 대한 **기여도(Contribution)** $\mathcal{E}$ 라고 정의함 :
   
    $$\begin{align} \mathcal{E}(\mathcal{G}_k, \mathrm{o}, \mathrm{r}) = \mathcal{G}_k^{1D}(t^*) \end{align}$$

      <img src="assets/img/posts_storage/GOF/IMG_5224166F295B-1.jpeg" width="500" alt="figure2">

<br>

#### Volume Rendering
- camera ray상의 **pixel color**는 Gaussian primitive의 depth로 정렬된 순서에 따라서 alpha blending을 통해 렌더링됨 
  
  $$\begin{align} \mathrm{c}(\mathrm{o}, \mathrm{r}) = \sum\limits_{k=1}^{K}\mathrm{c}_k\alpha_k\mathcal{E}(\mathcal{G}_k, \mathrm{o}, \mathrm{r})\prod\limits_{i=1}^{k-1}(1 - \alpha_j \mathcal{E}(\mathcal{G}_j, \mathrm{o}, \mathrm{r})) \end{align} $$

where, $c_k$ : *view-dependent color* modeled with spherical harmonics <br>
and $\alpha_k$ : additional parameter that influences the *opacity of Gaussian $k$.*

- **(tile-based rendering process)** 즉 standard 3DGS와 같이 depth 기반 alpha blending방식으로 pixel color rendering하는 방식 사용함
  
  <br>

### 2. Gaussian Opacity Fields
- projected 2D Gaussian대신 ray-Gaussian Intersection을 이용하기 때문에, ray에 존재하는 어떠한 점이라도 **opacity value**($\mathrm{O}_k(\mathcal{G}_k, \mathrm{o}, \mathrm{r}, t)$)를 구할 수 있다는 장점
  
  $$ \begin{align} \mathrm{O}_k(\mathcal{G}_k, \mathrm{o}, \mathrm{r}, t) = 
  \begin{cases}
  \mathcal{G}_k^{1D}(t) & \text{if } t \leq t^* \\
  \mathcal{G}_k^{1D}(t^*),  & \text{if } t  > t^*
  \end{cases} \end{align}$$

- 이렇게 구해진 ray상의 opacity value를 이용하여 **volume rendering process**는 아래 수식처럼 이루어짐 :

    $$\begin{align} \mathrm{O}(\mathrm{o}, \mathrm{r}, t) = \sum\limits_{k=1}^{K}\alpha_k \mathrm{O}_k(\mathcal{G}_k, \mathrm{o}, \mathrm{r}, t) \prod\limits_{i=1}^{k-1}(1 - \alpha_j \mathrm{O}_k(\mathcal{G}_k, \mathrm{o}, \mathrm{r}, t)) \end{align} $$

- 이 때 3D point는 모든 뷰에서 보여지는데, 3D point $\mathrm{x}$의 opacity는 이 모든 학습 뷰에 대한 opacity value 중 **최솟값**으로 정의한다.

    $$\begin{align} \mathrm{O(\mathrm{x})} = \min\limits_{(o, r)}\mathrm{O}(\mathrm{o}, \mathrm{r}, t) \end{align}$$

- 위의 $\mathrm{O(\mathrm{x})}$를 **<u>"Gaussian Opacity Fields(GOF)"</u>**라고 언급한다.
  - 이 GOF를 이용하면 poisson reconstruction이나 TSDF Fusion없이도 **surface**를 바로 추출할 수 있다.
  - by identifying their **level sets**
  - 본 논문에서 만든 Tetrahedral 기반 메쉬 추출 방법과 연결되어 사용함, 4.에 더 자세히 수록


<br>

### 3. Optimization
- 기본적으로 [2DGS](https://jyseo531.github.io/posts/2DGS/)에서 언급된 loss들(depth distortion, normal consistency loss)를 이용하여 정규화함
- 


<br>

### 4. Surface Extraction (Marching Tetrahedral)
- tetrahedral(다면체) 기반으로 그리드를 생성하여 메쉬 추출하는 알고리즘까지 개발해버림
- 이어서..



<br>

## Experiments

## 느낀점
